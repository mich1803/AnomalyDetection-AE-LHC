{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Group Project 2024/25\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8ix-CMEfVfV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task\n"
      ],
      "metadata": {
        "id": "Fs3lL8NouR0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Allenare un AE per Anomaly Detection in grado di riconoscere segnali prodotti da jeti adronici anomali in un reivelatore di fisica delle alte energie.\n",
        "\n",
        "Alle energie estreme del Large Hadron Collider, particelle massive possono essere prodotte con un tale boost di Lorentz da far sì che i loro decadimenti in adroni (getti adronici) risultino così collimati che le particelle prodotte si sovrappongono. Determinare se la sottostruttura di un getto osservato sia dovuta a una singola particella di bassa massa oppure a molteplici prodotti di decadimento di una particella di massa elevata è un problema cruciale nell’analisi dei dati del LHC. Gli approcci tradizionali si basano su osservabili di alto livello costruite a partire da modelli teorici di deposizione di energia nei calorimetri e da parametri delle tracce cariche ricostruite nel tracciatore interno, ma la complessità dei dati rende questo compito un candidato ideale per l’applicazione di strumenti di deep learning. I costituenti dei getti possono infatti essere rappresentati come immagini 2D in cui ogni pixel rappresenta una delle celle sensibili del calorimetro, e il contenuto della cella una misura dell'energia o della quantità di moto depositata nella cella.\n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "I dati del progetto sono nella forma di immagini 2D di dimensione (100,100), ogni cella rappresenta l'energia depositata in quella cella dalle particelle del jet adronico corrispondente. Ci sono due tipologie di jet adronici consider ati: *jet normali*, costituiti dalla adronizzazione di un quark leggero o gluone, e *jet anomali* (disponibili in una frazione incognita solo nel test set) costituiti dall'adronizzazione dei quark nel decadimento $t \\to Wb \\to qq'b$, in cui a causa del boost del quark top, i tre quark nello stato finale sono parzialmente sovrapposti.\n",
        "\n",
        "* *Normal data dataset:* 12k jet rappresentati come histogrammi 2D della quantità di moto depositata in ciascuno dei 100x100 bin di una finestra quadrata nel piano ($\\theta,\\phi$) centrato intorno all'asse del jet.\n",
        "\n",
        "* *Test dataset:*\n",
        "due dataset costituiti ciascuno da 3k eventi, contenenti jet normali e jet anomali in una frazione relativa icognita da determinare. Nel primo dataset (*_high*) la frazione incognita di eventi anomali è $\\ge 55\\%$. Nel secondo dataset (*_low*) la frazione incognita di eventi anomali incognita è $\\le 45\\%$.\n",
        "Potete utilizzare questa informazione per verificare che le vostre predizioni soddisfino la relazione $f_{high} > f_{low}$.\n",
        "\n",
        "I dati sono forniti come array numpy in un file numpy compresso (.npz), leggibile con l'esempio di codice che segue:\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "f_train = np.load('Normal_data.npz')\n",
        "f_test_l = np.load('Test_data_low.npz')\n",
        "f_test_h = np.load('Test_data_high.npz')\n",
        "\n",
        "normal_data = f_train['normal_data']\n",
        "test_data_l = f_test_l['test_data']\n",
        "test_data_h = f_test_h['test_data']\n",
        "\n",
        "print(normal_data.shape)\n",
        "print(test_data_l.shape)\n",
        "print(test_data_h.shape)\n",
        "```\n",
        "\n",
        "**Per scaricare i dataset:**\n",
        "* dati normali:\n",
        "```\n",
        "!wget http://giagu.web.cern.ch/giagu/CERN/P2025/Normal_data.npz\n",
        "```\n",
        "* dati anomali:\n",
        "```\n",
        "!wget http://giagu.web.cern.ch/giagu/CERN/P2025/<Identificativo Dataset>/Test_data_low.npz\n",
        "!wget http://giagu.web.cern.ch/giagu/CERN/P2025/<Identificativo Dataset>/Test_data_high.npz\n",
        "```\n",
        "```\n",
        "# <Identificativo Dataset> dal foglio excel prenotazione gruppi\n",
        "```\n",
        "\n",
        "\n",
        "**Obiettivi minimi del progetto (potete a vostro piacimento aggiungere ulteriori analisi/studi:**\n",
        "\n",
        "1. Plot della rappresentazione latente delle immagini di test fatto con riduzione dimensionale.\n",
        "2. Stima della frazione di eventi anomali presente nei due Test dataset, tenendo conto che la di procedura di stima deve garantire che la rate di falsi postivi sia inferiore a circa il $10\\%$ (FPR $\\le \\sim 10\\%$).\n",
        "3. Clustering dello spazio (per esempio usando un algoritmo GMM).\n",
        "4. Misura della purezza dei cluster rispetto alle label assegnate in anomaly score.\n",
        "\n",
        "\n",
        "**Nota Importante:**\n",
        "\n",
        "Il notebook deve essere compilato come una relazione scientifica del progetto, quindi deve contenere sia il codice (leggibile e riproducibile), i risultati in termini di grafici e tabelle numeriche, e il testo che illustra la strategia ottenuta, le scelte compiute, e i risultati ottenuti."
      ],
      "metadata": {
        "id": "ZtrtaHDwuV_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codice"
      ],
      "metadata": {
        "id": "jwlpgVGjuarB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importazione librerie, settaggio seed per la riproducibilità\n",
        "!pip install -q pytorch-lightning\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import pytorch_lightning as pl\n",
        "import torch.nn.functional as F\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "# Impostazioni per la riproducibilità\n",
        "SEED = 42\n",
        "pl.seed_everything(SEED, workers=True)\n",
        "\n",
        "# Device (CPU/GPU)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {DEVICE} device\")\n",
        "\n",
        "# Download dei dataset\n",
        "ID = \"G15\"\n",
        "!wget -nc http://giagu.web.cern.ch/giagu/CERN/P2025/Normal_data.npz\n",
        "!wget -nc http://giagu.web.cern.ch/giagu/CERN/P2025/{ID}/Test_data_low.npz\n",
        "!wget -nc http://giagu.web.cern.ch/giagu/CERN/P2025/{ID}/Test_data_high.npz"
      ],
      "metadata": {
        "id": "gKykx92QJO18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Caricamento dei Dataset/Dataloader e visualizzazione preliminare"
      ],
      "metadata": {
        "id": "AKQgMI5O0WZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creazione Datasets e DataLoader PyTorch\n",
        "\n",
        "f_train = np.load('Normal_data.npz')\n",
        "f_test_l = np.load('Test_data_low.npz')\n",
        "f_test_h = np.load('Test_data_high.npz')\n",
        "\n",
        "normal_data = f_train['normal_data']\n",
        "test_data_l = f_test_l['test_data']\n",
        "test_data_h = f_test_h['test_data']\n",
        "\n",
        "# Normalizzazione [0,1] usando solo il training set\n",
        "train_min = np.min(normal_data)\n",
        "train_max = np.max(normal_data)\n",
        "\n",
        "def normalize(data, data_min, data_max):\n",
        "    return (data - data_min) / (data_max - data_min + 1e-8)\n",
        "\n",
        "normal_data = normalize(normal_data, train_min, train_max)\n",
        "test_data_l = normalize(test_data_l, train_min, train_max)\n",
        "test_data_h = normalize(test_data_h, train_min, train_max)\n",
        "\n",
        "# Conversione in tensori torch\n",
        "normal_tensor = torch.tensor(normal_data, dtype=torch.float32).unsqueeze(1)\n",
        "test_tensor_l = torch.tensor(test_data_l, dtype=torch.float32).unsqueeze(1)\n",
        "test_tensor_h = torch.tensor(test_data_h, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Test datasets\n",
        "train_dataset = TensorDataset(normal_tensor)\n",
        "test_dataset_l = TensorDataset(test_tensor_l)\n",
        "test_dataset_h = TensorDataset(test_tensor_h)\n",
        "\n",
        "# DataLoader\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader_l = DataLoader(test_dataset_l, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader_h = DataLoader(test_dataset_h, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Info\n",
        "print(f\"Train: {len(train_dataset)} | Test Low: {len(test_dataset_l)} | Test High: {len(test_dataset_h)}\")\n",
        "\n",
        "datasets = {\n",
        "    \"Train (Normal)\": normal_data,\n",
        "    \"Test Low\": test_data_l,\n",
        "    \"Test High\": test_data_h\n",
        "}\n",
        "print(\"\\nLa normalizzazione tra 0 e 1 è basata sui dati di training:\")\n",
        "for name, data in datasets.items():\n",
        "    print(f\"{name}: min = {np.min(data):.4f}, max = {np.max(data):.4f}\")\n"
      ],
      "metadata": {
        "id": "zQCZXnjouGfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot di alcuni eventi del dataset\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10, 10))\n",
        "fig.suptitle(\"Primi 3 esempi per dataset (100x100)\\nScala dei colori locale per ciascuna immagine\", fontsize=14)\n",
        "\n",
        "for row_idx, (label, data) in enumerate(datasets.items()):\n",
        "    for col_idx in range(3):\n",
        "        ax = axes[row_idx, col_idx]\n",
        "        img = data[col_idx]\n",
        "        im = ax.imshow(img, cmap=\"inferno\", origin=\"lower\", vmin=np.min(img), vmax=np.max(img))\n",
        "        ax.axis(\"off\")\n",
        "        if col_idx == 0:\n",
        "            ax.set_title(label, fontsize=12, loc='left')\n",
        "\n",
        "fig.subplots_adjust(left=0.05, right=0.95, top=0.9, bottom=0.05, wspace=0.1, hspace=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ADkE7_elwPBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definizione del Modello e dei Parametri\n"
      ],
      "metadata": {
        "id": "47ZfbzL884h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Modello ConvAE\n",
        "\n",
        "class ConvAE(pl.LightningModule):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(config)\n",
        "        self.lr = config.get(\"lr\", 1e-3)\n",
        "        self.dropout = config.get(\"dropout\", 0.0)\n",
        "        hidden_dim = config[\"hidden_dim\"]\n",
        "\n",
        "        # Encoder\n",
        "        in_channels = 1\n",
        "        encoder_layers = []\n",
        "        for conv in config[\"in_conv\"]:\n",
        "            encoder_layers.append(nn.Conv2d(in_channels, **{k: v for k, v in conv.items() if k != \"output_padding\"}))\n",
        "            encoder_layers.append(nn.ReLU())\n",
        "            if self.dropout > 0:\n",
        "                encoder_layers.append(nn.Dropout2d(self.dropout))\n",
        "            in_channels = conv[\"out_channels\"]\n",
        "        self.encoder_conv = nn.Sequential(*encoder_layers)\n",
        "\n",
        "        # Calcola shape del bottleneck convoluzionale\n",
        "        dummy_input = torch.zeros(1, 1, 100, 100)\n",
        "        with torch.no_grad():\n",
        "            dummy_out = self.encoder_conv(dummy_input)\n",
        "            self.conv_shape = dummy_out.shape[1:]  # (C, H, W)\n",
        "            self.flat_dim = dummy_out.numel()\n",
        "\n",
        "        # Bottleneck FC\n",
        "        self.encoder_fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.flat_dim, hidden_dim)\n",
        "        )\n",
        "        self.decoder_fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, self.flat_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        decoder_layers = []\n",
        "        in_channels = config[\"in_conv\"][-1][\"out_channels\"]\n",
        "        for conv in config[\"out_conv\"]:\n",
        "            decoder_layers.append(nn.ConvTranspose2d(in_channels, **conv))\n",
        "            decoder_layers.append(nn.ReLU())\n",
        "            if self.dropout > 0:\n",
        "                decoder_layers.append(nn.Dropout2d(self.dropout))\n",
        "            in_channels = conv[\"out_channels\"]\n",
        "        decoder_layers[-2] = nn.Sigmoid()  # ultima attivazione\n",
        "        self.decoder_conv = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder_conv(x)\n",
        "        x = self.encoder_fc(x)\n",
        "        x = self.decoder_fc(x)\n",
        "        x = x.view(-1, *self.conv_shape)  # usa shape salvata\n",
        "        x = self.decoder_conv(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x = batch[0]\n",
        "        x_hat = self(x)\n",
        "        loss = F.mse_loss(x_hat, x)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
      ],
      "metadata": {
        "id": "oIPwVTGq89-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parametri S, M e L\n",
        "\n",
        "# Small (3D spazio latente)\n",
        "params_S = {\n",
        "    \"hidden_dim\": 3,\n",
        "    \"in_conv\": [\n",
        "        {\"out_channels\": 16, \"kernel_size\": 4, \"stride\": 2, \"padding\": 1},  # 100 → 50\n",
        "        {\"out_channels\": 32, \"kernel_size\": 4, \"stride\": 2, \"padding\": 1},  # 50 → 25\n",
        "        {\"out_channels\": 64, \"kernel_size\": 4, \"stride\": 2, \"padding\": 1}   # 25 → 13\n",
        "    ],\n",
        "    \"out_conv\": [\n",
        "        {\"out_channels\": 32, \"kernel_size\": 4, \"stride\": 2, \"padding\": 1, \"output_padding\": 1},  # 13 → 25\n",
        "        {\"out_channels\": 16, \"kernel_size\": 4, \"stride\": 2, \"padding\": 1, \"output_padding\": 0},  # 25 → 50\n",
        "        {\"out_channels\": 1,  \"kernel_size\": 4, \"stride\": 2, \"padding\": 1, \"output_padding\": 0}   # 50 → 100\n",
        "    ],\n",
        "    \"dropout\": 0.2,\n",
        "    \"lr\": 1e-3\n",
        "}\n",
        "\n",
        "# Large (32D spazio latente)\n",
        "params_L = {**params_S, \"hidden_dim\": 32}\n",
        "\n",
        "MAX_EPOCHS = 50\n",
        "PATIENCE = MAX_EPOCHS // 5\n"
      ],
      "metadata": {
        "id": "RxFOPJ_f-cpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modello S -> 3D"
      ],
      "metadata": {
        "id": "J3F04lVy_jUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inizializza il modello\n",
        "from torchsummary import summary\n",
        "model_S = ConvAE(params_S).to(DEVICE)\n",
        "\n",
        "# Supponendo input (1, 100, 100)\n",
        "summary(model_S, input_size=(1, 100, 100))"
      ],
      "metadata": {
        "id": "qAcAG8oOisFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training del modello Small\n",
        "\n",
        "model_S = ConvAE(params_S)\n",
        "\n",
        "early_stop_cb = EarlyStopping(\n",
        "    monitor=\"train_loss\",\n",
        "    patience=PATIENCE,\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    max_epochs=MAX_EPOCHS,\n",
        "    accelerator=\"auto\",\n",
        "    callbacks=[early_stop_cb],\n",
        "    log_every_n_steps=10\n",
        ")\n",
        "\n",
        "# Training\n",
        "trainer.fit(model_S, train_loader)\n"
      ],
      "metadata": {
        "id": "x9G4hl5f_gjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Confronto degli errori di ricostruzione: Test LOW, Test HIGH\n",
        "\n",
        "def compute_reconstruction_errors(model, dataloader):\n",
        "    model.eval()\n",
        "    errors = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            x = batch[0].to(model.device)\n",
        "            x_hat = model(x)\n",
        "            mse = F.mse_loss(x_hat, x, reduction='none')\n",
        "            mse_per_image = mse.view(mse.size(0), -1).mean(dim=1)\n",
        "            errors.extend(mse_per_image.cpu().numpy())\n",
        "    return np.array(errors)\n",
        "\n",
        "# Calcolo errori\n",
        "train_errors = compute_reconstruction_errors(model_S, train_loader)\n",
        "test_errors_l = compute_reconstruction_errors(model_S, test_loader_l)\n",
        "test_errors_h = compute_reconstruction_errors(model_S, test_loader_h)\n",
        "\n",
        "# Plot\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True, sharex=True)\n",
        "\n",
        "axs[0].hist(test_errors_l, bins=50, color='orange')\n",
        "axs[0].set_title(\"Test LOW\")\n",
        "axs[0].set_xlabel(\"MSE\")\n",
        "\n",
        "axs[1].hist(test_errors_h, bins=50, color='purple')\n",
        "axs[1].set_title(\"Test HIGH\")\n",
        "axs[1].set_xlabel(\"MSE\")\n",
        "\n",
        "plt.suptitle(\"Distribuzione degli errori di ricostruzione (MSE) per immagine\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nErrore medio di ricostruzione (MSE) sul training set: {train_errors.mean():.6f}\")\n",
        "print(f\"Errore medio di ricostruzione (MSE) sul test set LOW: {test_errors_l.mean():.6f}\")\n",
        "print(f\"Errore medio di ricostruzione (MSE) sul test set HIGH: {test_errors_h.mean():.6f}\")"
      ],
      "metadata": {
        "id": "HclMfdNfDRD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot interattivo 3D: Train+Val, Test LOW, Test HIGH con Plotly\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def extract_latents(dataloader, model):\n",
        "    latents = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            x = batch[0].to(model.device)\n",
        "            z = model.encoder_fc(model.encoder_conv(x))\n",
        "            latents.append(z.cpu().numpy())\n",
        "    return np.concatenate(latents, axis=0)\n",
        "\n",
        "# Estrazione\n",
        "latents_train = extract_latents(train_loader, model_S)\n",
        "latents_low = extract_latents(test_loader_l, model_S)\n",
        "latents_high = extract_latents(test_loader_h, model_S)\n",
        "\n",
        "# Funzione per creare uno scatter3D Plotly\n",
        "def plot_latents_plotly(latents, name, color):\n",
        "    return go.Scatter3d(\n",
        "        x=latents[:, 0], y=latents[:, 1], z=latents[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=2, color=color, opacity=0.6),\n",
        "        name=name\n",
        "    )\n",
        "\n",
        "# Subplots Plotly\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=3,\n",
        "    specs=[[{'type': 'scatter3d'}]*3],\n",
        "    subplot_titles=[\"Train\", \"Test LOW\", \"Test HIGH\"]\n",
        ")\n",
        "\n",
        "# Tracce\n",
        "fig.add_trace(plot_latents_plotly(latents_train, \"Train\", \"deepskyblue\"), row=1, col=1)\n",
        "fig.add_trace(plot_latents_plotly(latents_low, \"Test LOW\", \"orange\"), row=1, col=2)\n",
        "fig.add_trace(plot_latents_plotly(latents_high, \"Test HIGH\", \"purple\"), row=1, col=3)\n",
        "\n",
        "# Layout\n",
        "fig.update_layout(\n",
        "    height=600, width=1800,\n",
        "    title_text=\"Confronto Spazio Latente - Train+Val vs Test\",\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "pQ7rikRqNwDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modello L -> 32D"
      ],
      "metadata": {
        "id": "kifA-LR6RzSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_L = ConvAE(params_L).to(DEVICE)\n",
        "\n",
        "# Supponendo input (1, 100, 100)\n",
        "summary(model_L, input_size=(1, 100, 100))"
      ],
      "metadata": {
        "id": "Gt01G6a1j75U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training del modello Medium\n",
        "\n",
        "# Inizializza il modello\n",
        "model_L = ConvAE(params_L)\n",
        "\n",
        "early_stop_cb = EarlyStopping(\n",
        "    monitor=\"train_loss\",\n",
        "    patience=PATIENCE,\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    max_epochs=MAX_EPOCHS,\n",
        "    accelerator=\"auto\",\n",
        "    callbacks=[early_stop_cb],\n",
        "    log_every_n_steps=10\n",
        ")\n",
        "\n",
        "# Training\n",
        "trainer.fit(model_L, train_loader)\n"
      ],
      "metadata": {
        "id": "M_aJMCX5R7sV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}